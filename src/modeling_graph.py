import pandas as pd
import matplotlib.pyplot as plt
import networkx as nx
import numpy as np
import community.community_louvain as community_louvain
from networkx.algorithms.community import girvan_newman
from fa2_modified import ForceAtlas2 
import matplotlib
from scipy.stats import pearsonr
import sys
import os
import igraph as ig
from leidenalg import find_partition, ModularityVertexPartition
from networkx.algorithms.community import asyn_lpa_communities  

class HiddenPrints:
    def __enter__(self):
        self._original_stdout = sys.stdout
        sys.stdout = open(os.devnull, 'w')

    def __exit__(self, exc_type, exc_val, exc_tb):
        sys.stdout.close()
        sys.stdout = self._original_stdout

def grafico_bairro_casos(df_bairros, n):
    # Ordenar por nÃºmero de casos
    df_bairros = df_bairros.sort_values(by="N de casos Total", ascending=False)

    # Criar o grÃ¡fico de barras
    plt.figure(figsize=(12, 6))
    plt.bar(df_bairros["Bairro"][:n], df_bairros["N de casos Total"][:n], color="skyblue")
    plt.xticks(rotation=90, fontsize=9)  # Ajuste o tamanho do label do eixo X
    plt.xlabel("Bairros", fontsize=14)  # Ajuste o tamanho do label do eixo X
    plt.ylabel("NÃºmero de Casos", fontsize=14)  # Ajuste o tamanho do label do eixo Y
    plt.title("DistribuiÃ§Ã£o de Casos por Bairro (Top " + str(n) + ")", fontsize=16)  # Ajuste o tamanho do tÃ­tulo
    plt.grid(axis="y", linestyle="--", alpha=0.7)

    # Salvar o grÃ¡fico como um arquivo PNG
    file_path = "./datasets/graphs/grafico_bairro_casos_" + str(n) + ".png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")

    # Fechar a figura para liberar memÃ³ria
    plt.close()
    print("GrÃ¡fico salvo em", file_path)

def grafico_idade_casos(df_nodes):
    # plotar aas idades de cada caso de acordo com o seu respectivo bairro
    plt.figure(figsize=(10,7))
    plt.scatter(df_nodes["ID"], df_nodes["Idade Aparente"], color="skyblue", alpha=0.7)
    plt.ylim(0, None)  # Define o limite inferior como 0 e mantÃ©m o superior automÃ¡tico

    plt.xlabel("ID", fontsize=14)
    plt.ylabel("Idade Aparente", fontsize=14)

    plt.title("Idade Aparente por Caso", fontsize=16)
    plt.grid(linestyle="--", alpha=0.7)

    file_path = "./datasets/graphs/grafico_idade_casos.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")
    plt.close()

    print("GrÃ¡fico salvo em", file_path)

def grafico_cor_casos(df_nodes):
    df_nodes = df_nodes[df_nodes["Tipo"] == 1]
    # plotar aas cores de cada caso de acordo com o seu respectivo bairro
    plt.figure(figsize=(10,7))
    plt.bar(df_nodes["Bairro"], df_nodes["Raca Cor"], color="skyblue", alpha=0.7)

    plt.xlabel("Bairro", fontsize=14)
    plt.ylabel("Raca Cor", fontsize=14)

    plt.title("Raca Cor por Caso", fontsize=16)
    plt.grid(linestyle="--", alpha=0.7)

    file_path = "./datasets/graphs/grafico_cor_casos.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")
    plt.close()

    print("GrÃ¡fico salvo em", file_path)

def grafico_escolaridade_casos(df_nodes):
    df_nodes = df_nodes[df_nodes["Tipo"] == 1]
    # plotar aas escolaridades de cada caso de acordo com o seu respectivo bairro
    plt.figure(figsize=(10,7))
    plt.bar(df_nodes["Bairro"], df_nodes["Escolaridade"], color="skyblue", alpha=0.7)

    plt.xlabel("Bairro", fontsize=14)
    plt.ylabel("Escolaridade", fontsize=14)

    plt.title("Escolaridade por Caso", fontsize=16)
    plt.grid(linestyle="--", alpha=0.7)

    file_path = "./datasets/graphs/grafico_escolaridade_casos.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")
    plt.close()

    print("GrÃ¡fico salvo em", file_path)

def grafico_classificacao_casos(df_nodes):
    df_nodes = df_nodes[df_nodes["Tipo"] == 1]
    # plotar aas classificacoes de cada caso de acordo com o seu respectivo bairro
    plt.figure(figsize=(10,7))
    plt.bar(df_nodes["Bairro"], df_nodes["Classificacao"], color="skyblue", alpha=0.7)

    plt.xlabel("Bairro", fontsize=14)
    plt.ylabel("Classificacao", fontsize=14)

    plt.title("Classificacao por Caso", fontsize=16)
    plt.grid(linestyle="--", alpha=0.7)

    file_path = "./datasets/graphs/grafico_classificacao_casos.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")
    plt.close()

    print("GrÃ¡fico salvo em", file_path)

def grafico_media_idade_casos(df_idade, df_bairros, color_map):
    df_idade = df_idade.reset_index(drop=True)
    df_bairros = df_bairros.reset_index(drop=True)

    # ðŸ”¹ Criar o mapeamento de cores usando a comunidade detectada no grafo
    comunidades_unicas = df_bairros["Comunidade"].unique()

    # Usar as cores jÃ¡ atribuÃ­das no grafo, se disponÃ­veis
    mapa_cores = {comunidade: color_map.get(comunidade, "gray") for comunidade in comunidades_unicas}

    # ðŸ“Œ Criar grÃ¡fico da mÃ©dia de idade e nÃºmero de casos
    plt.figure(figsize=(10,7))

    for comunidade in comunidades_unicas:
        mask = df_bairros["Comunidade"] == comunidade
        plt.scatter(
            df_bairros.loc[mask, "N de casos Total"],
            df_idade.loc[mask, "Media Idade"],
            color=mapa_cores[comunidade],  # ðŸ”¹ Usar a mesma cor do grafo
            alpha=0.7,
            label=comunidade
        )

    plt.ylim(0, None)
    plt.xlabel("N de casos Total", fontsize=14)
    plt.ylabel("MÃ©dia de Idade", fontsize=14)
    plt.title("RelaÃ§Ã£o entre MÃ©dia de Idade e NÃºmero de Casos", fontsize=16)
    plt.grid(linestyle="--", alpha=0.7)
    plt.legend(title="Comunidade")

    file_path = "./datasets/graphs/grafico_media_idade_casos.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")
    plt.close()
    print("GrÃ¡fico salvo em", file_path)

    # ðŸ“Œ Criar grÃ¡fico do desvio padrÃ£o e nÃºmero de casos
    plt.figure(figsize=(10,7))

    for comunidade in comunidades_unicas:
        mask = df_bairros["Comunidade"] == comunidade
        plt.scatter(
            df_bairros.loc[mask, "N de casos Total"],
            df_idade.loc[mask, "Desvio Padrao Idade"],
            color=mapa_cores[comunidade],  # ðŸ”¹ Usar a mesma cor do grafo
            alpha=0.7,
            label=comunidade
        )

    plt.ylim(0, None)
    plt.xlabel("N de casos Total", fontsize=14)
    plt.ylabel("Desvio PadrÃ£o de Idade", fontsize=14)
    plt.title("RelaÃ§Ã£o entre Desvio PadrÃ£o de Idade e NÃºmero de Casos", fontsize=16)
    plt.grid(linestyle="--", alpha=0.7)
    plt.legend(title="Comunidade")

    file_path = "./datasets/graphs/grafico_desvio_padrao_idade_casos.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")
    plt.close()
    print("GrÃ¡fico salvo em", file_path)

def grafico_media_cor_casos(df_cor, df_nodes, color_map):
    df_cor = df_cor.reset_index(drop=True)
    df_nodes = df_nodes.reset_index(drop=True)

    # ðŸ”¹ Criar o mapeamento de cores usando a comunidade detectada no grafo
    comunidades_unicas = df_nodes["Comunidade"].unique()
    mapa_cores = {comunidade: color_map.get(comunidade, "gray") for comunidade in comunidades_unicas}

    # ðŸ“Œ Criar grÃ¡fico da mÃ©dia de cor e nÃºmero de casos
    plt.figure(figsize=(10,7))

    for comunidade in comunidades_unicas:
        mask = df_nodes["Comunidade"] == comunidade
        plt.scatter(
            df_nodes.loc[mask, "N de casos Total"],
            df_cor.loc[mask, "Cor Predominante"],
            color=mapa_cores[comunidade],
            alpha=0.7,
            label=comunidade
        )

    plt.ylim(0, 1)
    plt.xlabel("N de casos Total", fontsize=14)
    plt.ylabel("Cor Predominante", fontsize=14)
    plt.title("RelaÃ§Ã£o entre Cor Predominante e NÃºmero de Casos", fontsize=16)
    plt.grid(linestyle="--", alpha=0.7)
    plt.legend(title="Comunidade")

    file_path = "./datasets/graphs/grafico_media_cor_casos.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")
    plt.close()
    print("GrÃ¡fico salvo em", file_path)

    # ðŸ“Œ Criar grÃ¡fico do desvio padrÃ£o e nÃºmero de casos
    plt.figure(figsize=(10,7))

    for comunidade in comunidades_unicas:
        mask = df_nodes["Comunidade"] == comunidade
        plt.scatter(
            df_nodes.loc[mask, "N de casos Total"],
            df_cor.loc[mask, "Desvio Padrao Cor"],
            color=mapa_cores[comunidade],
            alpha=0.7,
            label=comunidade
        )

    plt.ylim(0, 1)
    plt.xlabel("N de casos Total", fontsize=14)
    plt.ylabel("Desvio PadrÃ£o de Cor", fontsize=14)
    plt.title("RelaÃ§Ã£o entre Desvio PadrÃ£o de Cor e NÃºmero de Casos", fontsize=16)
    plt.grid(linestyle="--", alpha=0.7)
    plt.legend(title="Comunidade")

    file_path = "./datasets/graphs/grafico_desvio_padrao_cor_casos.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")
    plt.close()
    print("GrÃ¡fico salvo em", file_path)

def grafico_media_escolaridade_casos(df_escolaridade, df_nodes, color_map):
    df_escolaridade = df_escolaridade.reset_index(drop=True)
    df_nodes = df_nodes.reset_index(drop=True)

    comunidades_unicas = df_nodes["Comunidade"].unique()
    mapa_cores = {comunidade: color_map.get(comunidade, "gray") for comunidade in comunidades_unicas}

    # ðŸ“Œ Criar grÃ¡fico da mÃ©dia de escolaridade e nÃºmero de casos
    plt.figure(figsize=(10,7))

    for comunidade in comunidades_unicas:
        mask = df_nodes["Comunidade"] == comunidade
        plt.scatter(
            df_nodes.loc[mask, "N de casos Total"],
            df_escolaridade.loc[mask, "Escolaridade Predominante"],
            color=mapa_cores[comunidade],
            alpha=0.7,
            label=comunidade
        )

    plt.ylim(0, 1)
    plt.xlabel("N de casos Total", fontsize=14)
    plt.ylabel("Escolaridade Predominante", fontsize=14)
    plt.title("RelaÃ§Ã£o entre Escolaridade Predominante e NÃºmero de Casos", fontsize=16)
    plt.grid(linestyle="--", alpha=0.7)
    plt.legend(title="Comunidade")

    file_path = "./datasets/graphs/grafico_escolaridade_casos.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")
    plt.close()
    print("GrÃ¡fico salvo em", file_path)

    # ðŸ“Œ Criar grÃ¡fico do desvio padrÃ£o e nÃºmero de casos
    plt.figure(figsize=(10,7))

    for comunidade in comunidades_unicas:
        mask = df_nodes["Comunidade"] == comunidade
        plt.scatter(
            df_nodes.loc[mask, "N de casos Total"],
            df_escolaridade.loc[mask, "Desvio Padrao Escolaridade"],
            color=mapa_cores[comunidade],
            alpha=0.7,
            label=comunidade
        )

    plt.ylim(0, 1)
    plt.xlabel("N de casos Total", fontsize=14)
    plt.ylabel("Desvio PadrÃ£o de Escolaridade", fontsize=14)
    plt.title("RelaÃ§Ã£o entre Desvio PadrÃ£o de Escolaridade e NÃºmero de Casos", fontsize=16)
    plt.grid(linestyle="--", alpha=0.7)
    plt.legend(title="Comunidade")

    file_path = "./datasets/graphs/grafico_desvio_padrao_escolaridade_casos.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")
    plt.close()
    print("GrÃ¡fico salvo em", file_path)

def grafico_media_classificacao_casos(df_classificacao, df_nodes, color_map):
    df_classificacao = df_classificacao.reset_index(drop=True)
    df_nodes = df_nodes.reset_index(drop=True)

    comunidades_unicas = df_nodes["Comunidade"].unique()
    mapa_cores = {comunidade: color_map.get(comunidade, "gray") for comunidade in comunidades_unicas}

    # ðŸ“Œ Criar grÃ¡fico da mÃ©dia de classificaÃ§Ã£o e nÃºmero de casos
    plt.figure(figsize=(10,7))

    for comunidade in comunidades_unicas:
        mask = df_nodes["Comunidade"] == comunidade
        plt.scatter(
            df_nodes.loc[mask, "N de casos Total"],
            df_classificacao.loc[mask, "Classificacao Predominante"],
            color=mapa_cores[comunidade],
            alpha=0.7,
            label=comunidade
        )

    plt.ylim(0, 1)
    plt.xlabel("N de casos Total", fontsize=14)
    plt.ylabel("ClassificaÃ§Ã£o Predominante", fontsize=14)
    plt.title("RelaÃ§Ã£o entre ClassificaÃ§Ã£o Predominante e NÃºmero de Casos", fontsize=16)
    plt.grid(linestyle="--", alpha=0.7)
    plt.legend(title="Comunidade")

    file_path = "./datasets/graphs/grafico_classificacao_casos.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")
    plt.close()
    print("GrÃ¡fico salvo em", file_path)

    # ðŸ“Œ Criar grÃ¡fico do desvio padrÃ£o e nÃºmero de casos
    plt.figure(figsize=(10,7))

    for comunidade in comunidades_unicas:
        mask = df_nodes["Comunidade"] == comunidade
        plt.scatter(
            df_nodes.loc[mask, "N de casos Total"],
            df_classificacao.loc[mask, "Desvio Padrao Classificacao"],
            color=mapa_cores[comunidade],
            alpha=0.7,
            label=comunidade
        )

    plt.ylim(0, 1)
    plt.xlabel("N de casos Total", fontsize=14)
    plt.ylabel("Desvio PadrÃ£o de ClassificaÃ§Ã£o", fontsize=14)
    plt.title("RelaÃ§Ã£o entre Desvio PadrÃ£o de ClassificaÃ§Ã£o e NÃºmero de Casos", fontsize=16)
    plt.grid(linestyle="--", alpha=0.7)
    plt.legend(title="Comunidade")

    file_path = "./datasets/graphs/grafico_desvio_padrao_classificacao_casos.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")
    plt.close()
    print("GrÃ¡fico salvo em", file_path)


def betweenness_centrality(df_nodes, df_edges):
    # ðŸ“Œ 2. Criar o Grafo
    G = nx.Graph()

    # Adicionar nÃ³s (bairros e casos)
    for _, row in df_nodes.iterrows():
        G.add_node(row["ID"], tipo=row["Tipo"])  # Tipo 2 = Bairro, Tipo 1 = Caso

    # Adicionar arestas com pesos
    for _, row in df_edges.iterrows():
        G.add_edge(row["Source"], row["Target"], weight=row["Weight"])

    # ðŸ“Œ 3. Calcular a Centralidade Betweenness para os bairros
    betweenness = nx.betweenness_centrality(G, weight="weight")

    # Criar um DataFrame com os resultados apenas para bairros (Tipo 2)
    bairros_betweenness = pd.DataFrame([
        {"ID": node, "Bairro": df_nodes.loc[df_nodes["ID"] == node, "Bairro"].values[0], 
        "Betweenness": betweenness[node]}
        for node in G.nodes if G.nodes[node]["tipo"] == 2
    ])

    # ðŸ“Œ 4. Salvar ou visualizar os resultados
    bairros_betweenness.to_csv("./datasets/bairros_betweenness.csv", index=False)
    print("Centralidade Betweenness salva em ./datasets/bairros_betweenness.csv")

def grafico_betweenness(df_bairros, n):
    # Ordenar por nÃºmero de casos
    df_bairros = df_bairros.sort_values(by="Betweenness", ascending=False)

    # Criar o grÃ¡fico de barras
    plt.figure(figsize=(12, 6))
    plt.bar(df_bairros["Bairro"][:n], df_bairros["Betweenness"][:n], color="skyblue")
    plt.xticks(rotation=90, fontsize=9)  # Ajuste o tamanho do label do eixo X
    plt.xlabel("Bairros", fontsize=14)  # Ajuste o tamanho do label do eixo X
    plt.ylabel("Betweenness", fontsize=14)  # Ajuste o tamanho do label do eixo Y
    plt.title("Centralidade Betweenness por Bairro (Top " + str(n) + ")", fontsize=16)  # Ajuste o tamanho do tÃ­tulo
    plt.grid(axis="y", linestyle="--", alpha=0.7)

    # Salvar o grÃ¡fico como um arquivo PNG
    file_path = "./datasets/graphs/grafico_betweenness_" + str(n) + ".png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")

    # Fechar a figura para liberar memÃ³ria
    plt.close()
    print("GrÃ¡fico salvo em", file_path)

def grafico_betweenness_casos(df_betweenness, df_bairros):
    # ðŸ“Œ 2. Unir os DataFrames de Betweenness e NÃºmero de Casos
    df_betweenness = df_betweenness.merge(df_bairros, how="left", left_on="ID", right_on="ID")

    # ðŸ“Œ 3. Criar o grÃ¡fico de dispersÃ£o
    plt.figure(figsize=(8, 8))
    plt.scatter(df_betweenness["Betweenness"], df_betweenness["N de casos Total"], color="skyblue", alpha=0.7)
    plt.xlabel("Betweenness", fontsize=14)  # Ajuste o tamanho do label do eixo X
    plt.ylabel("NÃºmero de Casos", fontsize=14)  # Ajuste o tamanho do label do eixo Y
    plt.title("Betweenness vs. NÃºmero de Casos por Bairro", fontsize=16)  # Ajuste o tamanho do tÃ­tulo
    plt.grid(linestyle="--", alpha=0.7)

    # Salvar o grÃ¡fico como um arquivo PNG
    file_path = "./datasets/graphs/grafico_betweenness_casos.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")

    # Fechar a figura para liberar memÃ³ria
    plt.close()
    print("GrÃ¡fico salvo em", file_path)

def closeness_centrality(df_nodes, df_edges):
    # ðŸ“Œ 2. Criar o Grafo
    G = nx.Graph()

    # Adicionar nÃ³s (bairros e casos)
    for _, row in df_nodes.iterrows():
        G.add_node(row["ID"], tipo=row["Tipo"])  # Tipo 2 = Bairro, Tipo 1 = Caso

    # Adicionar arestas com pesos
    for _, row in df_edges.iterrows():
        G.add_edge(row["Source"], row["Target"], weight=row["Weight"])

    # ðŸ“Œ 3. Calcular a Centralidade Closeness para os bairros
    closeness = nx.closeness_centrality(G, distance="weight")

    # Criar um DataFrame com os resultados apenas para bairros (Tipo 2)
    bairros_closeness = pd.DataFrame([
        {"ID": node, "Bairro": df_nodes.loc[df_nodes["ID"] == node, "Bairro"].values[0], 
        "Closeness": closeness[node]}
        for node in G.nodes if G.nodes[node]["tipo"] == 2
    ])

    # ðŸ“Œ 4. Salvar ou visualizar os resultados
    bairros_closeness.to_csv("./datasets/bairros_closeness.csv", index=False)
    print("Centralidade Closeness salva em ./datasets/bairros_closeness.csv")

def grafico_closeness(df_bairros, n):
    # Ordenar por nÃºmero de casos
    df_bairros = df_bairros.sort_values(by="Closeness", ascending=False)

    # Criar o grÃ¡fico de barras
    plt.figure(figsize=(12, 6))
    plt.bar(df_bairros["Bairro"][:n], df_bairros["Closeness"][:n], color="skyblue")
    plt.xticks(rotation=90, fontsize=9)  # Ajuste o tamanho do label do eixo X
    plt.xlabel("Bairros", fontsize=14)  # Ajuste o tamanho do label do eixo X
    plt.ylabel("Closeness", fontsize=14)  # Ajuste o tamanho do label do eixo Y
    plt.title("Centralidade Closeness por Bairro (Top " + str(n) + ")", fontsize=16)  # Ajuste o tamanho do tÃ­tulo
    plt.grid(axis="y", linestyle="--", alpha=0.7)

    # Salvar o grÃ¡fico como um arquivo PNG
    file_path = "./datasets/graphs/grafico_closeness_" + str(n) + ".png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")

    # Fechar a figura para liberar memÃ³ria
    plt.close()
    print("GrÃ¡fico salvo em", file_path)

def grafico_closeness_casos(df_closeness, df_bairros):
    # ðŸ“Œ 2. Unir os DataFrames de Closeness e NÃºmero de Casos
    df_closeness = df_closeness.merge(df_bairros, how="left", left_on="ID", right_on="ID")

    # ðŸ“Œ 3. Criar o grÃ¡fico de dispersÃ£o
    plt.figure(figsize=(8, 8))
    plt.scatter(df_closeness["Closeness"], df_closeness["N de casos Total"], color="skyblue", alpha=0.7)
    plt.xlabel("Closeness", fontsize=14)  # Ajuste o tamanho do label do eixo X
    plt.ylabel("NÃºmero de Casos", fontsize=14)  # Ajuste o tamanho do label do eixo Y
    plt.title("Closeness vs. NÃºmero de Casos por Bairro", fontsize=16)  # Ajuste o tamanho do tÃ­tulo
    plt.grid(linestyle="--", alpha=0.7)

    # Salvar o grÃ¡fico como um arquivo PNG
    file_path = "./datasets/graphs/grafico_closeness_casos.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")

    # Fechar a figura para liberar memÃ³ria
    plt.close()
    print("GrÃ¡fico salvo em", file_path)

def calcular_morans_i(df_nodes, df_edges):
    # ðŸ“Œ 2. Criar o Grafo de bairros
    G = nx.Graph()

    # Adicionar nÃ³s (apenas bairros)
    for _, row in df_nodes.iterrows():
        if row["Tipo"] == 2:  # Tipo 2 = Bairro
            G.add_node(row["ID"], casos=row["N de casos Total"])

    # Adicionar arestas (apenas conexÃµes entre bairros, peso 2)
    for _, row in df_edges.iterrows():
        if row["Weight"] == 2:
            G.add_edge(row["Source"], row["Target"])

    # ðŸ“Œ 3. Criar a matriz de adjacÃªncia normalizada
    matriz_adj = nx.to_numpy_array(G, nodelist=sorted(G.nodes()))  # Matriz de vizinhanÃ§a
    matriz_pesos = matriz_adj / matriz_adj.sum(axis=1, keepdims=True)  # Normaliza pelos vizinhos

    # ðŸ“Œ 4. Criar vetor de casos de violÃªncia
    casos = np.array([G.nodes[n]["casos"] for n in sorted(G.nodes())])

    # ðŸ“Œ 5. Calcular Moran's I
    N = len(casos)
    media_casos = np.mean(casos)

    numerador = 0
    for i in range(N):
        for j in range(N):
            numerador += matriz_pesos[i, j] * (casos[i] - media_casos) * (casos[j] - media_casos)

    denominador = np.sum((casos - media_casos) ** 2)

    morans_i = (N / matriz_pesos.sum()) * (numerador / denominador)

    print(f"Moranâ€™s I calculado: {morans_i:.4f}")
    
    if morans_i > 0.6:
        print("AutocorrelaÃ§Ã£o espacial positiva e significativa.")
    elif morans_i > 0 and morans_i < 0.6:
        print("AutocorrelaÃ§Ã£o espacial positiva, mas nÃ£o significativa.")
    elif morans_i < 0:
        print("AutocorrelaÃ§Ã£o espacial negativa, ou seja os bairros com mais casos estÃ£o rodeados por bairros com menos casos.")

def calcular_pagerank(df_nodes, df_edges, damping=0.85, max_iter=100, tol=1e-6):
    # ðŸ“Œ 2. Criar o Grafo de bairros
    G = nx.Graph()

    # Adicionar nÃ³s (somente bairros)
    for _, row in df_nodes.iterrows():
        if row["Tipo"] == 2:  # Tipo 2 = Bairro
            G.add_node(row["ID"], bairro=row["Bairro"])

    # Adicionar arestas (somente conexÃµes entre bairros, peso 2)
    for _, row in df_edges.iterrows():
        if row["Weight"] == 2:
            G.add_edge(row["Source"], row["Target"])

    # ðŸ“Œ 3. Calcular PageRank
    pagerank = nx.pagerank(G, alpha=damping, max_iter=max_iter, tol=tol)

    # Criar um DataFrame com os resultados
    pagerank_df = pd.DataFrame([
        {"ID": node, "Bairro": G.nodes[node]["bairro"], "PageRank": pagerank[node]}
        for node in G.nodes
    ]).sort_values(by="PageRank", ascending=False)

    # ðŸ“Œ 4. Salvar os resultados
    output_file = "./datasets/bairros_pagerank.csv"
    pagerank_df.to_csv(output_file, index=False)
    print(f"PageRank calculado e salvo em: {output_file}")

def grafico_pagerank(df_pagerank, n):
    # Ordenar por PageRank
    df_pagerank = df_pagerank.sort_values(by="PageRank", ascending=False)

    # Criar o grÃ¡fico de barras
    plt.figure(figsize=(12, 6))
    plt.bar(df_pagerank["Bairro"][:n], df_pagerank["PageRank"][:n], color="skyblue")
    plt.xticks(rotation=90, fontsize=9)  # Ajuste o tamanho do label do eixo X
    plt.xlabel("Bairros", fontsize=14)  # Ajuste o tamanho do label do eixo X
    plt.ylabel("PageRank", fontsize=14)  # Ajuste o tamanho do label do eixo Y
    plt.title("PageRank por Bairro (Top " + str(n) + ")", fontsize=16)  # Ajuste o tamanho do tÃ­tulo
    plt.grid(axis="y", linestyle="--", alpha=0.7)

    # Salvar o grÃ¡fico como um arquivo PNG
    file_path = "./datasets/graphs/grafico_pagerank_" + str(n) + ".png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")

    # Fechar a figura para liberar memÃ³ria
    plt.close()
    print("GrÃ¡fico salvo em", file_path)

def grafico_pagerank_casos(df_pagerank, df_bairros):
    # ðŸ“Œ 2. Unir os DataFrames de PageRank e NÃºmero de Casos
    df_pagerank = df_pagerank.merge(df_bairros, how="left", left_on="ID", right_on="ID")

    # ðŸ“Œ 3. Criar o grÃ¡fico de dispersÃ£o
    plt.figure(figsize=(8, 8))
    plt.scatter(df_pagerank["PageRank"], df_pagerank["N de casos Total"], color="skyblue", alpha=0.7)
    plt.xlabel("PageRank", fontsize=14)  # Ajuste o tamanho do label do eixo X
    plt.ylabel("NÃºmero de Casos", fontsize=14)  # Ajuste o tamanho do label do eixo Y
    plt.title("PageRank vs. NÃºmero de Casos por Bairro", fontsize=16)  # Ajuste o tamanho do tÃ­tulo
    plt.grid(linestyle="--", alpha=0.7)

    # Salvar o grÃ¡fico como um arquivo PNG
    file_path = "./datasets/graphs/grafico_pagerank_casos.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")

    # Fechar a figura para liberar memÃ³ria
    plt.close()
    print("GrÃ¡fico salvo em", file_path)

def pearson_correlation_coefficient(df_nodes, df_edges):
    # ðŸ“Œ 1. Criar o Grafo
    G = nx.Graph()

    # Adicionar nÃ³s (bairros apenas)
    for _, row in df_nodes.iterrows():
        if row["Tipo"] == 2:  # Apenas bairros
            G.add_node(row["ID"], tipo="bairro", casos=row["N de casos Total"])

    # Adicionar arestas (somente entre bairros - peso 2)
    for _, row in df_edges.iterrows():
        if row["Weight"] == 2:
            G.add_edge(row["Source"], row["Target"], weight=row["Weight"])

    # ðŸ“Œ 2. Criar um dicionÃ¡rio para armazenar a mÃ©dia de casos dos vizinhos
    media_casos_vizinhos = {}
    desvio_casos_vizinhos = {}

    for bairro in G.nodes:
        vizinhos = [n for n in G.neighbors(bairro) if G.nodes[n]["tipo"] == "bairro"]
        if vizinhos:
            casos_vizinhos = [G.nodes[v]["casos"] for v in vizinhos]
            media_casos_vizinhos[bairro] = np.mean(casos_vizinhos)
            desvio_casos_vizinhos[bairro] = np.std(casos_vizinhos)  # Desvio padrÃ£o dos vizinhos
        else:
            media_casos_vizinhos[bairro] = 0
            desvio_casos_vizinhos[bairro] = 0

    # Criar um DataFrame com os resultados individuais por bairro
    bairros_df = pd.DataFrame([
        {"ID": bairro, 
         "Bairro": df_nodes.loc[df_nodes["ID"] == bairro, "Bairro"].values[0],
         "Casos": G.nodes[bairro]["casos"], 
         "Media Casos Vizinhos": media_casos_vizinhos[bairro],
         "Desvio Casos Vizinhos": desvio_casos_vizinhos[bairro],
         "Diferenca Percentual": ((G.nodes[bairro]["casos"] - media_casos_vizinhos[bairro]) / 
                                  (media_casos_vizinhos[bairro] + 1e-6)) * 100  # Evitar divisÃ£o por zero
        }
        for bairro in G.nodes
    ])

    # ðŸ“Œ 3. Salvar os resultados em um arquivo CSV
    bairros_df.to_csv("./datasets/bairros_assortatividade.csv", index=False)
    print("CorrelaÃ§Ã£o individual por bairro salva em ./datasets/bairros_assortatividade.csv")

def grafico_assortatividade(df_bairros, n):
    # Ordenar por diferenÃ§a percentual
    df_bairros = df_bairros.sort_values(by="Diferenca Percentual", ascending=False)

    # Criar o grÃ¡fico de barras
    plt.figure(figsize=(12, 6))
    plt.bar(df_bairros["Bairro"][:n], df_bairros["Diferenca Percentual"][:n], color="skyblue")
    plt.xticks(rotation=90, fontsize=9)  # Ajuste o tamanho do label do eixo X
    plt.xlabel("Bairros", fontsize=14)  # Ajuste o tamanho do label do eixo X
    plt.ylabel("DiferenÃ§a Percentual", fontsize=14)  # Ajuste o tamanho do label do eixo Y
    plt.title("Assortatividade por Bairro (Top " + str(n) + ")", fontsize=16)  # Ajuste o tamanho do tÃ­tulo
    plt.grid(axis="y", linestyle="--", alpha=0.7)

    # Salvar o grÃ¡fico como um arquivo PNG
    file_path = "./datasets/graphs/grafico_assortatividade_" + str(n) + ".png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")

    # Fechar a figura para liberar memÃ³ria
    plt.close()
    print("GrÃ¡fico salvo em", file_path)

def calcular_pvalor_assortatividade(df_assortatividade):
    """
    LÃª a correlaÃ§Ã£o de Pearson jÃ¡ calculada e salva no arquivo bairros_assortatividade.csv,
    e testa a significÃ¢ncia estatÃ­stica (p-valor).
    
    ParÃ¢metros:
    - df_assortatividade: DataFrame contendo os valores jÃ¡ calculados.

    Retorno:
    - CorrelaÃ§Ã£o de Pearson e p-valor.
    """
    # ðŸ“Œ 1. Obter os valores jÃ¡ calculados
    casos_bairros = df_assortatividade["Casos"].values
    media_casos_vizinhos = df_assortatividade["Media Casos Vizinhos"].values

    # ðŸ“Œ 2. Calcular a correlaÃ§Ã£o de Pearson e o p-valor
    correlacao, p_valor = pearsonr(casos_bairros, media_casos_vizinhos)

    print(f"CorrelaÃ§Ã£o de Pearson: {correlacao:.4f}")
    print(f"P-valor: {p_valor:.4f}")
    
    return correlacao, p_valor

def teste_permutacao_assortatividade(df_assortatividade, n_permutacoes=1000):
    """
    Testa se a correlaÃ§Ã£o observada entre os casos nos bairros e seus vizinhos Ã© estatisticamente significativa
    usando um teste de permutaÃ§Ã£o.

    ParÃ¢metros:
    - df_assortatividade: DataFrame contendo os valores jÃ¡ calculados.
    - n_permutacoes: nÃºmero de permutaÃ§Ãµes para o teste.

    Retorno:
    - p-valor da permutaÃ§Ã£o.
    """
    # ðŸ“Œ 1. Obter a correlaÃ§Ã£o real jÃ¡ calculada
    correlacao_real, _ = calcular_pvalor_assortatividade(df_assortatividade)

    # ðŸ“Œ 2. Teste de PermutaÃ§Ã£o
    permutacoes = []
    
    for _ in range(n_permutacoes):
        # Embaralhar os valores dos casos entr  e os bairros
        casos_embaralhados = np.random.permutation(df_assortatividade["Casos"].values)

        # Calcular a correlaÃ§Ã£o de Pearson na permutaÃ§Ã£o
        permutacao_corr, _ = pearsonr(casos_embaralhados, df_assortatividade["Media Casos Vizinhos"].values)
        permutacoes.append(permutacao_corr)

    # ðŸ“Œ 3. Calcular p-valor da permutaÃ§Ã£o
    p_valor_perm = np.sum(np.abs(permutacoes) >= np.abs(correlacao_real)) / n_permutacoes

    print(f"P-valor do teste de permutaÃ§Ã£o: {p_valor_perm:.4f}")

    # ðŸ“Œ 4. Interpretar o resultado
    if p_valor_perm < 0.05:
        print("A correlaÃ§Ã£o Ã© estatisticamente significativa com o teste de permutaÃ§Ã£o (p < 0.05).")
    else:
        print("A correlaÃ§Ã£o NÃƒO Ã© estatisticamente significativa com o teste de permutaÃ§Ã£o (p >= 0.05).")

def detectar_comunidades(df_nodes, df_edges):
    # ðŸ“Œ 1. Criar o Grafo
    G = nx.Graph()

    # Adicionar nÃ³s (bairros apenas)
    for _, row in df_nodes.iterrows():
        if row["Tipo"] == 2:  # Apenas bairros
            G.add_node(row["ID"], tipo="bairro", bairro=row["Bairro"])

    # Adicionar arestas (somente entre bairros - peso 2)
    for _, row in df_edges.iterrows():
        if row["Weight"] == 2:
            G.add_edge(row["Source"], row["Target"], weight=row["Weight"])

    # ðŸ“Œ 2. Aplicar diferentes mÃ©todos de detecÃ§Ã£o de comunidade

    ## 2.1 Girvan-Newman (Baseado em remoÃ§Ã£o de arestas)
    comp_gn = girvan_newman(G)  # Agora chamando do lugar correto
    first_level_gn = next(comp_gn, None)
    if first_level_gn:
        communities_gn = {node: i for i, community in enumerate(first_level_gn) for node in community}
    else:
        communities_gn = {}


    ## 2.2 Louvain (Baseado em otimizaÃ§Ã£o da modularidade)
    partition_louvain = community_louvain.best_partition(G)
    
    ## 2.3 Label Propagation (Baseado em propagaÃ§Ã£o de rÃ³tulos)
    communities_lp = {node: i for i, community in enumerate(asyn_lpa_communities(G)) for node in community}

    ## 2.4 Leiden (Baseado em modularidade, similar ao Louvain, mas mais eficiente)
    # Converter NetworkX para iGraph (Leiden precisa dessa estrutura)
    # Criar um dicionÃ¡rio para mapear IDs originais para Ã­ndices do iGraph
    # Criar uma lista de arestas e nÃ³s para o iGraph
    nodes_list = list(G.nodes)
    edges_list = list(G.edges)

    # Criar um grafo iGraph com os mesmos nÃ³s e arestas do NetworkX
    ig_G = ig.Graph(edges_list, directed=False)

    # Criar um dicionÃ¡rio para mapear Ã­ndices do iGraph para IDs originais do NetworkX
    node_mapping = {i: nodes_list[i] for i in range(len(nodes_list))}

    # Aplicar Leiden
    partition_leiden = find_partition(ig_G, ModularityVertexPartition)

    # Converter as comunidades do Leiden de volta para os IDs originais
    communities_leiden = {node_mapping[node]: i for i, community in enumerate(partition_leiden) for node in community}



    # ðŸ“Œ 3. Criar um DataFrame com as Comunidades detectadas
    comunidades_df = pd.DataFrame([
        {"ID": bairro,
         "Bairro": G.nodes[bairro]["bairro"],
         "Comunidade Girvan-Newman": communities_gn.get(bairro, -1),
         "Comunidade Louvain": partition_louvain.get(bairro, -1),
         "Comunidade Label Propagation": communities_lp.get(bairro, -1),
         "Comunidade Leiden": communities_leiden.get(bairro, -1)}
        for bairro in G.nodes
    ])

    # ðŸ“Œ 4. Salvar os resultados em um arquivo CSV
    comunidades_df.to_csv("./datasets/bairros_comunidades.csv", index=False)
    print("DetecÃ§Ã£o de comunidades salva em ./datasets/bairros_comunidades.csv")

def grafo_por_comunidade(df_nodes, df_edges, df_communities, name):
    # ðŸ“Œ 2. Criar o Grafo Geral
    G = nx.Graph()

    # Criar um dicionÃ¡rio para armazenar o nÃºmero de casos de cada bairro
    casos_por_bairro = {row["ID"]: row["N de casos Total"] for _, row in df_nodes.iterrows() if row["Tipo"] == 2}

    # Normalizar o tamanho dos nÃ³s (evita valores muito grandes ou pequenos)
    min_size = 50   # Tamanho mÃ­nimo do nÃ³
    max_size = 2000  # Tamanho mÃ¡ximo do nÃ³

    if casos_por_bairro:
        max_casos = max(casos_por_bairro.values())
        min_casos = min(casos_por_bairro.values())

        # Ajustar tamanho proporcional (evitar divisÃ£o por zero)
        tamanho_nos = {
            node: min_size + ((casos - min_casos) / (max_casos - min_casos + 1e-6)) * (max_size - min_size)
            for node, casos in casos_por_bairro.items()
        }
    else:
        tamanho_nos = {node: min_size for node in G.nodes()}  # Caso nÃ£o haja dados

    # Adicionar nÃ³s ao grafo
    for _, row in df_nodes.iterrows():
        if row["Tipo"] == 2:  # Apenas bairros
            G.add_node(row["ID"], bairro=row["Bairro"])

    # Adicionar arestas (somente entre bairros - peso 2)
    for _, row in df_edges.iterrows():
        if row["Weight"] == 2:
            G.add_edge(row["Source"], row["Target"])

    # ðŸ“Œ 3. Mapear comunidades Girvan-Newman
    comunidade_map = dict(zip(df_communities["ID"], df_communities["Comunidade"]))

    # ðŸ“Œ 4. Criar subgrafos por comunidade
    unique_communities = set(comunidade_map.values())
    color_map = {
        community: matplotlib.colormaps.get_cmap("tab10")(i / len(unique_communities)) 
        for i, community in enumerate(unique_communities)
    }

    # Criar um dicionÃ¡rio {ID: Nome do Bairro}
    label_map = {row["ID"]: row["Bairro"] for _, row in df_nodes.iterrows() if row["Tipo"] == 2}

    # # Criar um layout ForceAtlas2 para cada comunidade
    # for community in unique_communities:
    #     subgraph_nodes = [node for node in G.nodes if comunidade_map[node] == community]
    #     SG = G.subgraph(subgraph_nodes)

    #     if len(SG.nodes) > 1:  # Evita comunidades isoladas de um Ãºnico nÃ³
    #         forceatlas2 = ForceAtlas2(
    #             outboundAttractionDistribution=True,
    #             jitterTolerance=1.0,
    #             barnesHutOptimize=True,
    #             barnesHutTheta=1.2,
    #             scalingRatio=2.0,
    #             strongGravityMode=False,
    #             gravity=1.0
    #         )

    #         # Gerar posiÃ§Ãµes usando ForceAtlas2
    #         with HiddenPrints():
    #             pos = forceatlas2.forceatlas2_networkx_layout(SG, iterations=2000)

    #         # Criar cores para os nÃ³s da comunidade
    #         node_colors = [color_map[community] for _ in SG.nodes]

    #         # ðŸ“Œ 5. Plotar cada comunidade separadamente
    #         plt.figure(figsize=(10, 7))
            
    #         # Desenhar os nÃ³s e arestas
    #         nx.draw(SG, pos, with_labels=False, node_size=[tamanho_nos.get(node, min_size) for node in SG.nodes],
    #                 node_color=node_colors, edge_color="gray", alpha=0.8)
            
    #         # ðŸ”¹ Exibir nomes dos bairros nos nÃ³s
    #         nx.draw_networkx_labels(SG, pos, labels={node: label_map.get(node, "Desconhecido") for node in SG.nodes}, font_size=4)

         
    #     if len(SG.nodes) == 1:
    #         print(f"Comunidade {community} possui apenas um nÃ³ isolado!")

    #         # Capturar o Ãºnico nÃ³
    #         single_node = list(SG.nodes)[0]
            
    #         plt.figure(figsize=(10, 7))
    #         nx.draw_networkx_nodes(SG, pos={single_node: (0, 0)}, 
    #                             node_size=tamanho_nos.get(single_node, min_size), 
    #                             node_color=[color_map[community]])

    #         nx.draw_networkx_labels(SG, pos={single_node: (0, 0)}, 
    #                     labels={single_node: label_map.get(single_node, "Desconhecido")}, 
    #                     font_size=4)


    #         plt.axis("off")
    #         plt.gca().set_frame_on(False)

    #     plt.title(f"ForceAtlas2 - Comunidade {community} - " + name)
    #     file_path = f"./datasets/graphs/{name}/comunidade_{community}.png"
    #     plt.savefig(file_path,format="png", dpi=300, bbox_inches="tight")
    #     print(f"Comunidade {community} salva em {file_path}")
    #     plt.close()

    # ðŸ“Œ 3.1 Remover comunidades isoladas com poucos nÃ³s
    min_nos_por_comunidade = 10  # Defina um valor adequado
    contagem_por_comunidade = {}

    # Contar quantos nÃ³s existem em cada comunidade
    for node in list(G.nodes):
        comunidade = comunidade_map.get(node, -1)
        if comunidade != -1:
            contagem_por_comunidade[comunidade] = contagem_por_comunidade.get(comunidade, 0) + 1

    # Filtrar comunidades com poucos nÃ³s
    comunidades_validas = {com for com, count in contagem_por_comunidade.items() if count >= min_nos_por_comunidade}

    # ðŸ“Œ 3.2 Atualizar comunidade_map removendo referÃªncias a comunidades invÃ¡lidas
    comunidade_map_filtrado = {node: com for node, com in comunidade_map.items() if com in comunidades_validas}

    # ðŸ“Œ Remover nÃ³s que pertencem a comunidades invÃ¡lidas
    for node in list(G.nodes):
        if node not in comunidade_map_filtrado:
            G.remove_node(node)

    # ðŸ“Œ 4. Criar subgrafos por comunidade (apenas as vÃ¡lidas)
    unique_communities = set(comunidade_map_filtrado.values())

    # Criar o color_map apenas para comunidades vÃ¡lidas
    color_map = {
        community: matplotlib.colormaps.get_cmap("tab10")(i / len(unique_communities)) 
        for i, community in enumerate(unique_communities)
    }

    # colocar -1 para os bairros que as suas comunidades foram tiradas, em df_communities
    for _, row in df_communities.iterrows():
        if row["Comunidade"] not in comunidades_validas:
            df_communities.at[_, "Comunidade"] = -1

    # ðŸ“Œ 6. Aplicar ForceAtlas2 no Grafo Geral
    forceatlas2_global = ForceAtlas2(
        outboundAttractionDistribution=True,
        jitterTolerance=20.0,  # Deixa os nÃ³s mais espalhados
        barnesHutOptimize=True,
        barnesHutTheta=1.2,
        scalingRatio=50.0,  # Aumenta a separaÃ§Ã£o dos nÃ³s
        strongGravityMode=False,
        gravity=1  # Reduz a gravidade para deixar o layout mais disperso
    )

    # Gerar posiÃ§Ãµes globais usando ForceAtlas2
    with HiddenPrints():
        pos_global = forceatlas2_global.forceatlas2_networkx_layout(G, iterations=3000)

    # Criar cores para os nÃ³s globais e definir tamanho proporcional ao nÃºmero de casos
    node_colors_global = [color_map[comunidade_map_filtrado[node]] for node in G.nodes if node in comunidade_map_filtrado]
    node_sizes_global = [tamanho_nos.get(node, min_size) for node in G.nodes]

    # ðŸ“Œ 7. Plotar o Grafo Geral
    # Criar um dicionÃ¡rio {ID: Nome do Bairro}

    plt.figure(figsize=(10, 7))

    # Desenhar os nÃ³s e arestas
    nx.draw(G, pos_global, with_labels=False, node_size=node_sizes_global, node_color=node_colors_global, edge_color="gray", alpha=0.8)

    # ðŸ”¹ Exibir nomes dos bairros nos nÃ³s
    nx.draw_networkx_labels(G, pos_global, labels={node: label_map.get(node, "Desconhecido") for node in G.nodes}, font_size=4)

    # ConfiguraÃ§Ã£o do grÃ¡fico
    plt.title("ForceAtlas2 - Grafo Geral de Comunidades - " + name)
    file_path = "./datasets/graphs/" + name + "/grafo_geral_" + name + ".png"

    # Salvar a imagem sem espaÃ§os desnecessÃ¡rios
    plt.savefig(file_path, format="png", dpi=300, bbox_inches="tight")

    print("ðŸ“Œ Grafo Geral de Comunidades salvo em", file_path)
    plt.close()

    return color_map, df_communities

def grafico_comunidade(df_communities, df_aux, name, coluna):
    # ðŸ“Œ 2. Unir os DataFrames de Comunidade e NÃºmero de Casos
    df_communities = df_communities.merge(df_aux, how="left", left_on="ID", right_on="ID")

    # valor_comunidade = df_communities["Comunidade"].unique()
    # # somar os valores de da coluna para cada comunidade
    # somas = []
    # for i in valor_comunidade:
    #     # bairros com a mesma comunidade
    #     bairros = df_communities[df_communities["Comunidade"] == i]
    #     soma = 0 
    #     for _, row in bairros.iterrows():
    #         soma += row[coluna]
    #     somas.append(soma)

    # print(somas)

    # ðŸ“Œ 3. Criar o grÃ¡fico de dispersÃ£o
    plt.figure(figsize=(10, 7))
    # plt.scatter(valor_comunidade, somas, color="skyblue", alpha=0.7)
    plt.scatter(df_communities["Comunidade"], df_aux[coluna], color="skyblue", alpha=0.7)
    name1 = "Comunidade " + name
    plt.xlabel(name1, fontsize=14)  # Ajuste o tamanho do label do eixo X
    plt.ylabel(coluna, fontsize=14)  # Ajuste o tamanho do label do eixo Y
    plt.title(name1 + " vs. " + coluna, fontsize=16)  # Ajuste o tamanho do tÃ­tulo
    plt.grid(linestyle="--", alpha=0.7)

    # Salvar o grÃ¡fico como um arquivo PNG
    file_path = "./datasets/graphs/" + name + "/grafico_" + name1 + "_" + coluna + ".png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")

    # Fechar a figura para liberar memÃ³ria
    plt.close()
    print("GrÃ¡fico salvo em", file_path)

def normalizar_bairros(df_bairros):
    # Tirar bairros estremos, ou com 0 casos ou com muito altos, ou seja muito maior do q a maioria
    # ðŸ“Œ 1. Normalizar os dados
    df_bairros = df_bairros[(df_bairros["N de casos Total"] > 0)]

    media = df_bairros["N de casos Total"].mean()

    maximo = df_bairros["N de casos Total"].max()

    df_bairros = df_bairros[(df_bairros["N de casos Total"] < 12 * media)]

    # ðŸ“Œ 2. Salvar 
    df_bairros.to_csv("./datasets/bairros_normalizados.csv", index=False)
    print("Bairros normalizados salvos em ./datasets/bairros_normalizados.csv")

    return df_bairros

def media_idade(df_nodes, df_aux):
    """
    Calcula a mÃ©dia e o desvio padrÃ£o da idade para cada bairro, garantindo que os IDs sejam inteiros e comparÃ¡veis.
    """

    # Remover valores NaN antes de converter para inteiro
    df_nodes = df_nodes.dropna(subset=["Bairro"]).reset_index(drop=True)
    df_aux = df_aux.dropna(subset=["ID"]).reset_index(drop=True)

    # Converter apenas os bairros onde Tipo == 1 para inteiros, garantindo que nÃ£o haja espaÃ§os
    df_nodes.loc[df_nodes["Tipo"] == 1, "Bairro"] = df_nodes.loc[df_nodes["Tipo"] == 1, "Bairro"].astype(str).str.strip().astype(int)

    # Converter IDs de df_aux para inteiro (garantindo limpeza de espaÃ§os)
    df_aux["ID"] = df_aux["ID"].astype(str).str.strip().astype(int)

    for i in range(len(df_aux)):
        idades = []
        id_bairro_aux = int(df_aux.at[i, "ID"])  # Converter para int

        for j in range(len(df_nodes)):
            if df_nodes.at[j, "Tipo"] == 1:  # Considerando apenas pessoas
                bairro = int(df_nodes.at[j, "Bairro"])  # Converter para int

                if bairro == id_bairro_aux:  # Agora ambos sÃ£o int
                    idade = df_nodes.at[j, "Idade Aparente"]
                    if idade != -1:
                        idades.append(idade)

        if idades:
            media_idade = int(np.mean(idades))  # MÃ©dia como nÃºmero inteiro
            desvio_padrao = round(np.std(idades, ddof=0), 2)  # Desvio padrÃ£o com 2 casas decimais
        else:
            media_idade = -1
            desvio_padrao = -1

        df_aux.at[i, "Media Idade"] = media_idade
        df_aux.at[i, "Desvio Padrao Idade"] = desvio_padrao


    df_aux.to_csv("./datasets/media_idade.csv", index=False)
    print("MÃ©dia e desvio padrÃ£o de idade salvo em ./datasets/media_idade.csv")

    return df_aux

def media_cor(df_nodes, df_aux):
    """
    Calcula a cor predominante e o desvio padrÃ£o da distribuiÃ§Ã£o de cores para um bairro.
    """

    # Garantir que os IDs dos bairros em df_aux sejam inteiros e bem formatados
    df_aux["ID"] = df_aux["ID"].astype(str).str.strip().astype(int)

    # Criar dicionÃ¡rios para armazenar os resultados
    cor_predominante = {}
    desvio_padrao_cor = {}

    # Filtrar apenas as pessoas (Tipo == 1) e converter "Bairro" para inteiro apenas nesses casos
    df_pessoas = df_nodes[df_nodes["Tipo"] == 1].copy()
    df_pessoas.loc[:, "Bairro"] = df_pessoas["Bairro"].astype(str).str.strip().astype(int)

    # Agrupar por bairro e cor para contar quantas pessoas de cada cor existem
    contagem_cores = df_pessoas.groupby(["Bairro", "Raca Cor"]).size().reset_index(name="Quantidade")

    for _, row in df_aux.iterrows():
        bairro_id = row["ID"]

        # Filtrar apenas as contagens desse bairro
        cores_bairro = contagem_cores[contagem_cores["Bairro"] == bairro_id]

        if not cores_bairro.empty:
            # Encontrar a cor predominante
            cor_mais_comum = cores_bairro.loc[cores_bairro["Quantidade"].idxmax(), "Raca Cor"]
            cor_predominante[bairro_id] = cor_mais_comum

            # Calcular as proporÃ§Ãµes de cada cor no bairro
            total = cores_bairro["Quantidade"].sum()
            proporcoes = cores_bairro["Quantidade"] / total

            # Calcular desvio padrÃ£o das proporÃ§Ãµes
            desvio_padrao = round(np.sqrt(np.sum(proporcoes * (1 - proporcoes))), 4)
            desvio_padrao_cor[bairro_id] = desvio_padrao
        else:
            cor_predominante[bairro_id] = "DESCONHECIDO"
            desvio_padrao_cor[bairro_id] = -1  # Sem dados

    # Aplicar os resultados no DataFrame df_aux sem gerar `SettingWithCopyWarning`
    df_aux = df_aux.copy()
    df_aux["Cor Predominante"] = df_aux["ID"].map(cor_predominante)
    df_aux["Desvio Padrao Cor"] = df_aux["ID"].map(desvio_padrao_cor)

    # Salvar CSV com os resultados
    df_aux.to_csv("./datasets/media_cor.csv", index=False)
    print("Cor predominante salva em ./datasets/media_cor.csv")

    return df_aux

def media_escolaridade(df_nodes, df_aux):
    """
    Calcula a escolaridade predominante e o desvio padrÃ£o da distribuiÃ§Ã£o de escolaridade para um bairro.
    """

    # Garantir que os IDs dos bairros em df_aux sejam inteiros e bem formatados
    df_aux["ID"] = df_aux["ID"].astype(str).str.strip().astype(int)

    # Criar dicionÃ¡rios para armazenar os resultados
    escolaridade_predominante = {}
    desvio_padrao_escolaridade = {}

    # Filtrar apenas as pessoas (Tipo == 1) e converter "Bairro" para inteiro apenas nesses casos
    df_pessoas = df_nodes[df_nodes["Tipo"] == 1].copy()
    df_pessoas.loc[:, "Bairro"] = df_pessoas["Bairro"].astype(str).str.strip().astype(int)

    # Agrupar por bairro e escolaridade para contar quantas pessoas de cada nÃ­vel escolar existem
    contagem_escolaridade = df_pessoas.groupby(["Bairro", "Escolaridade"]).size().reset_index(name="Quantidade")

    for _, row in df_aux.iterrows():
        bairro_id = row["ID"]

        # Filtrar apenas as contagens desse bairro
        escolaridade_bairro = contagem_escolaridade[contagem_escolaridade["Bairro"] == bairro_id]

        if not escolaridade_bairro.empty:
            # Encontrar a escolaridade predominante
            escolaridade_mais_comum = escolaridade_bairro.loc[escolaridade_bairro["Quantidade"].idxmax(), "Escolaridade"]
            escolaridade_predominante[bairro_id] = escolaridade_mais_comum

            # Calcular as proporÃ§Ãµes de cada escolaridade no bairro
            total = escolaridade_bairro["Quantidade"].sum()
            proporcoes = escolaridade_bairro["Quantidade"] / total

            # Calcular desvio padrÃ£o das proporÃ§Ãµes
            desvio_padrao = round(np.sqrt(np.sum(proporcoes * (1 - proporcoes))), 4)
            desvio_padrao_escolaridade[bairro_id] = desvio_padrao
        else:
            escolaridade_predominante[bairro_id] = "DESCONHECIDO"
            desvio_padrao_escolaridade[bairro_id] = -1  # Sem dados

    # Aplicar os resultados no DataFrame df_aux sem gerar `SettingWithCopyWarning`
    df_aux = df_aux.copy()
    df_aux["Escolaridade Predominante"] = df_aux["ID"].map(escolaridade_predominante)
    df_aux["Desvio Padrao Escolaridade"] = df_aux["ID"].map(desvio_padrao_escolaridade)

    # Salvar CSV com os resultados
    df_aux.to_csv("./datasets/media_escolaridade.csv", index=False)
    print("Escolaridade predominante salva em ./datasets/media_escolaridade.csv")

    return df_aux

def media_classificacao(df_nodes, df_aux):
    # Garantir que os IDs dos bairros em df_aux sejam inteiros e bem formatados
    df_aux["ID"] = df_aux["ID"].astype(str).str.strip().astype(int)

    # Criar dicionÃ¡rios para armazenar os resultados
    classificacao_predominante = {}
    desvio_padrao_classificacao = {}

    # Filtrar apenas as pessoas (Tipo == 1) e converter "Bairro" para inteiro apenas nesses casos
    df_pessoas = df_nodes[df_nodes["Tipo"] == 1].copy()
    df_pessoas.loc[:, "Bairro"] = df_pessoas["Bairro"].astype(str).str.strip().astype(int)

    # Agrupar por bairro e classificacao para contar quantas pessoas de cada nÃ­vel escolar existem
    contagem_classificacao = df_pessoas.groupby(["Bairro", "Classificacao"]).size().reset_index(name="Quantidade")

    for _, row in df_aux.iterrows():
        bairro_id = row["ID"]

        # Filtrar apenas as contagens desse bairro
        classificacao_bairro = contagem_classificacao[contagem_classificacao["Bairro"] == bairro_id]

        if not classificacao_bairro.empty:
            # Encontrar a classificacao predominante
            classificacao_mais_comum = classificacao_bairro.loc[classificacao_bairro["Quantidade"].idxmax(), "Classificacao"]
            classificacao_predominante[bairro_id] = classificacao_mais_comum

            # Calcular as proporÃ§Ãµes de cada classificacao no bairro
            total = classificacao_bairro["Quantidade"].sum()
            proporcoes = classificacao_bairro["Quantidade"] / total

            # Calcular desvio padrÃ£o das proporÃ§Ãµes
            desvio_padrao = round(np.sqrt(np.sum(proporcoes * (1 - proporcoes))), 4)
            desvio_padrao_classificacao[bairro_id] = desvio_padrao
        else:
            classificacao_predominante[bairro_id] = "DESCONHECIDO"
            desvio_padrao_classificacao[bairro_id] = -1  # Sem dados

    # Aplicar os resultados no DataFrame df_aux sem gerar `SettingWithCopyWarning`
    df_aux = df_aux.copy()
    df_aux["Classificacao Predominante"] = df_aux["ID"].map(classificacao_predominante)
    df_aux["Desvio Padrao Classificacao"] = df_aux["ID"].map(desvio_padrao_classificacao)

    # Salvar CSV com os resultados
    df_aux.to_csv("./datasets/media_classificacao.csv", index=False)
    print("classificacao predominante salva em ./datasets/media_classificacao.csv")

    return df_aux

def grafico_idade_grau_casos(df_nodes):
    # Filtrar apenas as pessoas (Tipo == 1)
    df_pessoas = df_nodes[df_nodes["Tipo"] == 1]

    # ðŸ“Œ 1. Criar o grÃ¡fico de dispersÃ£o
    plt.figure(figsize=(10, 7))
    plt.scatter(df_pessoas["Idade Aparente"], df_pessoas["Classificacao"], color="skyblue", alpha=0.7)
    plt.xlabel("Idade", fontsize=14)  # Ajuste o tamanho do label do eixo X
    plt.ylabel("ClassificaÃ§Ã£o", fontsize=14)  # Ajuste o tamanho do label do eixo Y
    plt.title("Idade vs. ClassificaÃ§Ã£o", fontsize=16)  # Ajuste o tamanho do tÃ­tulo
    plt.grid(linestyle="--", alpha=0.7)

    # Salvar o grÃ¡fico como um arquivo PNG
    file_path = "./datasets/graphs/grafico_idade_classificacao.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")

    # Fechar a figura para liberar memÃ³ria
    plt.close()

    print("GrÃ¡fico salvo em", file_path)

def grafico_media_idade_grau_casos(df_idade, df_classificacao):
    # Ordenar por mÃ©dia de idade
    df_idade = df_idade.sort_values(by="Media Idade", ascending=False)

    # ðŸ“Œ 1. Criar o grÃ¡fico de barras
    plt.figure(figsize=(12, 6))
    plt.scatter(df_idade["Media Idade"], df_classificacao["Classificacao Predominante"], color="skyblue", alpha=0.7)
    plt.xlabel("MÃ©dia de Idade", fontsize=14)  # Ajuste o tamanho do label do eixo X
    plt.ylabel("ClassificaÃ§Ã£o Predominante", fontsize=14)  # Ajuste o tamanho do label do eixo Y    
    plt.title("MÃ©dia de Idade vs. ClassificaÃ§Ã£o Predominante", fontsize=16)  # Ajuste o tamanho do tÃ­tulo
    plt.grid(linestyle="--", alpha=0.7)

    # Salvar o grÃ¡fico como um arquivo PNG
    file_path = "./datasets/graphs/grafico_media_idade_classificacao.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")

    # Fechar a figura para liberar memÃ³ria
    plt.close()

    print("GrÃ¡fico salvo em", file_path)
    
def main():
    # Carregar os dados do arquivo nodes.csv
    df_bairros = pd.read_csv("./datasets/nodes_bairros.csv") 
    grafico_bairro_casos(df_bairros, 10)
    
    # estudo da dispersÃ£o dos casos em relaÃ§Ã£o a idadae, raca/cor e escolaridade
    # primeiro tirar bairros com numeros muito estremos de casos, ou 0 ou muito alto
    df_bairros = normalizar_bairros(df_bairros)

    # Carregar os dados dos arquivos nodes.csv e edges.csv
    df_nodes = pd.read_csv("./datasets/nodes.csv")
    df_edges = pd.read_csv("./datasets/edges.csv")

    # ðŸ“Œ 1. Calcular MÃ©tricas
    # centralidade de betweenness para entender a importÃ¢ncia dos bairros
    betweenness_centrality(df_nodes, df_edges)
    df_betweenness = pd.read_csv("./datasets/bairros_betweenness.csv")
    grafico_betweenness(df_betweenness, 10)
    grafico_betweenness_casos(df_betweenness, df_bairros)

    # centralidade de closeness para entender a proximidade dos bairros de acordo com a quantidade de casos
    closeness_centrality(df_nodes, df_edges)
    df_closeness = pd.read_csv("./datasets/bairros_closeness.csv")
    grafico_closeness(df_closeness, 10)
    grafico_closeness_casos(df_closeness, df_bairros)
    
    # morans i para entender a autocorrelaÃ§Ã£o espacial dos casos
    calcular_morans_i(df_nodes, df_edges)

    # pagerank para entender a importÃ¢ncia dos bairros
    calcular_pagerank(df_nodes, df_edges)
    df_pagerank = pd.read_csv("./datasets/bairros_pagerank.csv")
    grafico_pagerank(df_pagerank, 10)
    grafico_pagerank_casos(df_pagerank, df_bairros)

    # coeficiente de correlaÃ§Ã£o de Pearson para entender a relaÃ§Ã£o entre a quantidade de casos dos bairros e seus vizinhos
    pearson_correlation_coefficient(df_nodes, df_edges)
    df_assortatividade = pd.read_csv("./datasets/bairros_assortatividade.csv")
    grafico_assortatividade(df_assortatividade, 10)

    # p-valor para entender a significÃ¢ncia estatÃ­stica da correlaÃ§Ã£o de Pearson
    correlacao, p_valor = calcular_pvalor_assortatividade(df_assortatividade)
    # ðŸ“Œ 3. Interpretar o p-valor
    if p_valor < 0.05:
        print("A correlaÃ§Ã£o Ã© estatisticamente significativa (p < 0.05).")
    else:
        print("A correlaÃ§Ã£o NÃƒO Ã© estatisticamente significativa (p >= 0.05).")

    # teste de permutaÃ§Ã£o para entender a significÃ¢ncia estatÃ­stica da correlaÃ§Ã£o de Pearson
    teste_permutacao_assortatividade(df_assortatividade)
    
    # ðŸ“Œ 2. Detectar Comunidades
    detectar_comunidades(df_nodes, df_edges)
    df_comunidades = pd.read_csv("./datasets/bairros_comunidades.csv")
    # gerar grÃ¡ficos para cada modelo de comunidade

    color_map = {}
    for df in [df_comunidades["Comunidade Girvan-Newman"], df_comunidades["Comunidade Louvain"], df_comunidades["Comunidade Label Propagation"], df_comunidades["Comunidade Leiden"]]:
        df_aux = pd.DataFrame()
        df_aux["ID"] = df_comunidades["ID"]
        df_aux["Bairro"] = df_comunidades["Bairro"]
        df_aux["Comunidade"] = df
        # name Ã© o algoritmo de comunidade
        name = "Girvan-Newman" if df is df_comunidades["Comunidade Girvan-Newman"] else "Louvain" if df is df_comunidades["Comunidade Louvain"] else "Label Propagation" if df is df_comunidades["Comunidade Label Propagation"] else "Leiden"
        aux, df_aux1 = grafo_por_comunidade(df_nodes, df_edges, df_aux, name)

        if name == "Leiden":
            color_map = aux
            df_bairros["Comunidade"] = df_aux1["Comunidade"]
        
        i = 0
        for df_aux1 in [df_nodes[df_nodes["Tipo"] == 2], df_betweenness, df_closeness, df_pagerank, df_assortatividade]:
            coluna = "N de casos Total" if i == 0 else "Diferenca Percentual" if i == 4 else df_aux1.columns[2]
            print(coluna)   
            grafico_comunidade(df_aux, df_aux1, name, coluna)
            i += 1

    # Definir a cor branca para a comunidade -1
    color_map[-1] = (1.0, 1.0, 1.0, 1.0)  # Branco em formato RGBA


    df_aux = pd.DataFrame()
    df_aux["ID"] = df_bairros["ID"]
    df_aux["Bairro"] = df_bairros["Bairro"]
    df_idade = media_idade(df_nodes, df_aux)
    df_cor = media_cor(df_nodes, df_aux)
    df_escolaridade = media_escolaridade(df_nodes, df_aux)

    df_idade = pd.read_csv("./datasets/media_idade.csv")
    df_cor = pd.read_csv("./datasets/media_cor.csv")
    df_escolaridade = pd.read_csv("./datasets/media_escolaridade.csv")

    grafico_idade_casos(df_nodes)
    grafico_cor_casos(df_nodes)
    grafico_escolaridade_casos(df_nodes)

    # gerar grÃ¡ficos para cada mÃ©trica
    # graficos idade e numero de casos
    
    grafico_media_idade_casos(df_idade, df_bairros, color_map)

    # grafico cor predominante e numero de casos
    grafico_media_cor_casos(df_cor, df_bairros, color_map)

    # grafico escolaridade predominante e numero de casos
    grafico_media_escolaridade_casos(df_escolaridade, df_bairros, color_map)

    df_classificacao = media_classificacao(df_nodes, df_aux)
    grafico_classificacao_casos(df_nodes)
    grafico_media_classificacao_casos(df_classificacao, df_bairros, color_map)


    # analisar a correlaÃ§Ã£o entre as mÃ©tricas
    grafico_idade_grau_casos(df_nodes)
    grafico_media_idade_grau_casos(df_idade, df_classificacao)
                                   
if __name__ == "__main__":
    main()